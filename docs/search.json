[{"path":"index.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"repository (GitHub / OSF) contains data code required reproduce analyses reported manuscript, Time spent playing video games unlikely impact well-(Vuorre, Johannes, Magnusson, & Przybylski, 2021). analyses presented Online analysis supplement.","code":""},{"path":"index.html","id":"materials","chapter":"1 Introduction","heading":"1.1 Materials","text":"Preprint\npublicly available version manuscript advance peer-review formal publication\npublicly available version manuscript advance peer-review formal publicationGitHub repository\nversion controlled repository containing raw data code project\nversion controlled repository containing raw data code projectOSF repository\narchived permanent copy GitHub repository\narchived permanent copy GitHub repositoryOnline analysis supplement\noutput document analyses\noutput document analysesIn addition raw data, repository contains many survey telemetry variables analyse, may interest analyses gameplay well .","code":""},{"path":"index.html","id":"reproducibility","chapter":"1 Introduction","heading":"1.2 Reproducibility","text":"raw data Data/ directory repository. code used clean analyse data organised R Markdown (.Rmd) files directory, meant run sequence indicated numeric prefixes. run cleaning analyses, compile resulting document (online analysis supplement), run bookdown::render_book() R click “Build Book” RStudio IDE.","code":""},{"path":"index.html","id":"docker","chapter":"1 Introduction","heading":"1.2.1 Docker","text":"ensure reproducibility analyses, can use Docker:Build Docker imageRun container render output","code":"docker build \\\n    --build-arg R_VERSION=4.1.1 \\\n    --build-arg RENV_VERSION=0.14.0 \\\n    -t gametime-longitudinal .docker run \\\n    --rm \\\n    -v \"$(pwd):/home/\" \\\n    -v \"/home/renv/library\" \\\n    -e MAX_CORES=1 \\\n    gametime-longitudinal \\\n    R -e 'renv::restore(prompt = FALSE); bookdown::render_book()'"},{"path":"data-wrangling.html","id":"data-wrangling","chapter":"2 Data wrangling","heading":"2 Data wrangling","text":"visualising modelling, clean raw survey behavioural (telemetry) data. , also “define” participants excluding raw data individuals didn’t respond single survey item, didn’t play data six week duration. Lack play data indicates “active players”, target population study.first load required R packages.set options plots parallel computations.","code":"\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(janitor)\nlibrary(here)\nlibrary(scales)\nlibrary(lubridate)\nlibrary(gtsummary)\nlibrary(multidplyr)\nlibrary(showtext)\nlibrary(tidyverse)\nlibrary(sessioninfo)\n# Plotting options\nFont <- \"Titillium Web\"\nfont_add_google(Font, Font)\ntheme_set(\n  theme_linedraw(\n    base_family = Font,\n    base_size = 12\n  ) +\n    theme(\n      panel.grid.minor = element_blank(),\n      panel.grid.major.x = element_blank()\n    )\n)\n\n# parallel computations\nMAX_CORES <- as.numeric(Sys.getenv(\"MAX_CORES\"))\nif (is.na(MAX_CORES)) MAX_CORES <- parallel::detectCores(logical = FALSE)\ncluster <- new_cluster(MAX_CORES)\n# load packages on clusters\ncluster_library(cluster, c(\"dplyr\", \"lubridate\"))\n\n# For saving intermediate files\ndir.create(\"Temp\", FALSE)"},{"path":"data-wrangling.html","id":"survey","chapter":"2 Data wrangling","heading":"2.1 Survey","text":"table Data/qualtrics.csv.gz contains raw survey data, except excluded respondents didn’t consent withdrew study. proceed now clean file.","code":"\n# read_csv() automatically decompresses the .gz archive\nd <- read_csv(here(\"Data\", \"qualtrics.csv.gz\"))\n\n# Clean responses to the question asking if they played in past 2 weeks\nd <- d %>%\n  mutate(played = factor(!str_detect(played, \"NOT\")))\n\n# Create estimated time played variable from reported hours & mins\nd <- d %>%\n  mutate(minutes = minutes / 60) %>%\n  mutate(\n    hours_est = rowSums(select(., hours, minutes), na.rm = TRUE)\n  ) %>%\n  # sum above returns 0 if both hours and minutes are NA, fix here:\n  mutate(\n    hours_est = if_else(is.na(hours) & is.na(minutes), NaN, hours_est)\n  ) %>%\n  select(-minutes, -hours)\n\n# Ensure correct ordering and variable type of item responses\nspane_levels <- c(\n  \"Very rarely or never\",\n  \"Rarely\",\n  \"Occasionally\",\n  \"Sometimes\",\n  \"Frequently\",\n  \"Often\",\n  \"Very often or always\"\n)\npens_levels <- c(\n  \"Strongly disagree\",\n  \"Disagree\",\n  \"Somewhat disagree\",\n  \"Neither agree nor disagree\",\n  \"Somewhat agree\",\n  \"Agree\",\n  \"Strongly agree\"\n)\nd <- d %>%\n  mutate(\n    across(\n      starts_with(\"spane_\"),\n      function(x) {\n        factor(\n          x,\n          levels = spane_levels\n        )\n      }\n    )\n  )\nd <- d %>%\n  mutate(\n    across(\n      starts_with(\"pens_\"),\n      function(x) {\n        factor(\n          x,\n          levels = pens_levels\n        )\n      }\n    )\n  )\n\n# Convert item responses to numbers\nd <- d %>%\n  mutate(\n    across(\n      c(starts_with(\"spane_\"), starts_with(\"pens_\")),\n      as.numeric\n    )\n  )\n\n# Reverse reverse-scored items\nreverse_items <- c(\n  \"pens_needs_9\",\n  \"pens_motivations_2\",\n  \"pens_motivations_3\"\n)\nd <- d %>%\n  mutate(\n    across(all_of(reverse_items), ~ 8 - .x)\n  )\n\n# Subscale items\nspane_pos_items <- paste0(\"spane_\", c(1, 3, 5, 7, 10, 12))\nspane_neg_items <- paste0(\"spane_\", c(2, 4, 6, 8, 9, 11))\nautonomy_items <- paste0(\"pens_needs_\", 1:3)\ncompetence_items <- paste0(\"pens_needs_\", 4:6)\nrelatedness_items <- paste0(\"pens_needs_\", 7:9)\nintrinsic_items <- paste0(\"pens_motivations_\", 1:4)\nextrinsic_items <- paste0(\"pens_motivations_\", 5:8)\n\n# Create (sub)scale scores (means of item responses)\nd <- d %>%\n  mutate(\n    spane_pos = rowMeans(\n      select(., all_of(spane_pos_items)),\n      na.rm = TRUE\n    ),\n    spane_neg = rowMeans(\n      select(., all_of(spane_neg_items)),\n      na.rm = TRUE\n    ),\n    spane = spane_pos - spane_neg,\n    intrinsic = rowMeans(\n      select(., all_of(intrinsic_items)),\n      na.rm = TRUE\n    ),\n    extrinsic = rowMeans(\n      select(., all_of(extrinsic_items)),\n      na.rm = TRUE\n    ),\n    autonomy = rowMeans(\n      select(., all_of(autonomy_items)),\n      na.rm = TRUE\n    ),\n    competence = rowMeans(\n      select(., all_of(competence_items)),\n      na.rm = TRUE\n    ),\n    relatedness = rowMeans(\n      select(., all_of(relatedness_items)),\n      na.rm = TRUE\n    ),\n  )\n\n# Then remove and rename variables\nd <- d %>%\n  select(\n    -all_of(\n      c(\n        spane_pos_items,\n        spane_neg_items,\n        autonomy_items,\n        competence_items,\n        relatedness_items,\n        intrinsic_items,\n        extrinsic_items\n      )\n    )\n  )\n\n# Abbreviate long game names\nd <- d %>%\n  mutate(\n    game = ifelse(game == \"Animal Crossing: New Horizons\", \"AC:NH\", game)\n  )\n\n# Gender as factor\nd <- d %>%\n  mutate(gender = factor(gender))\n\n# Prettier names for tables/figures\nd <- d %>%\n  rename(\n    Affect = spane,\n    `Life satisfaction` = csas\n  ) %>%\n  rename_with(\n    str_to_title,\n    c(played:experience, game, company, intrinsic:relatedness)\n  )\n\n# Make table easier to look at by including only variables we need\n# in a reasonable order\nd <- d %>%\n  select(\n    Game, pid, wid,\n    Affect, `Life satisfaction`,\n    Intrinsic, Extrinsic, hours_est,\n    StartDate, Age, Gender, Experience\n  ) %>%\n  arrange(Game, pid, wid)"},{"path":"data-wrangling.html","id":"exclude-non-responders","chapter":"2 Data wrangling","heading":"2.1.1 Exclude non-responders","text":"point remove respond items wave. example “participants” simply clicked consent buttons exited survey. defines participant combination telemetry, . (best run speed computations .)\nTable 2.1: Summary participants without responses.\nCalculate exact interval survey waves person x waveWe clean table relevant survey responses, ready joined game play behaviour data (telemetry), .","code":"\n# Person-wave level indicator if person answered any survey questions at wave\nd$Responded <- apply(\n  select(d, Affect, `Life satisfaction`, Intrinsic, Extrinsic), 1,\n  function(x) sum(!is.na(x)) > 0\n)\n\n# Person-level indicator of how many waves responded to\nd <- d %>%\n  group_by(Game, pid) %>%\n  mutate(\n    `# of waves with response` = sum(Responded),\n    `Any waves with response` = factor(`# of waves with response` > 0)\n  ) %>%\n  ungroup()\n\n# Table of waves answered to by game\nd %>%\n  distinct(\n    Game, pid,\n    `# of waves with response`,\n    `Any waves with response`\n  ) %>%\n  select(-pid) %>%\n  tbl_summary(by = Game) %>%\n  add_overall() %>%\n  as_kable_extra(\n    caption = \"Summary of participants with and without responses.\"\n  ) %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n# Take out all who didn't answer a single wave\nd <- filter(d, `Any waves with response` == \"TRUE\")\n\n# Remove the indicators\nd <- select(d, -`# of waves with response`, -`Any waves with response`)\nsurvey_intervals <- d %>%\n  select(Game, pid, wid, StartDate) %>%\n  arrange(pid, wid) %>%\n  # Make sure that there is a row for each subject X wave\n  # so interval is calculated correctly\n  complete(wid, nesting(pid, Game)) %>%\n  arrange(pid, wid) %>%\n  group_by(pid) %>%\n  partition(cluster) %>%\n  # Interval between waves in days\n  mutate(\n    interval = (as.numeric(StartDate) - as.numeric(lag(StartDate))) /\n      3600 / 24\n  ) %>%\n  collect() %>%\n  ungroup() %>%\n  select(wid, pid, Game, interval)\nd <- left_join(d, survey_intervals)"},{"path":"data-wrangling.html","id":"telemetry","chapter":"2 Data wrangling","heading":"2.2 Telemetry","text":"first load game behaviour data sets, saved game-specific compressed comma-separated value files. files minimally processed versions ones received publishers. (Players didn’t explicitly consent survey excluded, variable names harmonised, tables reshaped format.)Merge games tables one table","code":"\n# Animal Crossing\nt_acnh <- read_csv(here(\"Data\", \"telemetry-acnh.csv.gz\")) %>%\n  mutate(Game = \"AC:NH\")\n\n# Apex Legends\nt_al <- read_csv(here(\"Data\", \"telemetry-apex-legends.csv.gz\"))\n# Select relevant variables\nt_al <- t_al %>%\n  select(\n    pid, session_start, session_end\n  ) %>%\n  # Format datetimes\n  transmute(\n    pid,\n    session_start = as_datetime(mdy_hm(session_start), tz = \"UTC\"),\n    session_end = as_datetime(mdy_hm(session_end), tz = \"UTC\"),\n    Game = \"Apex Legends\"\n  )\n\n# Forza Horizon 4\nt_fh <- read_csv(here(\"Data\", \"telemetry-forza-horizon-4.csv.gz\"))\nt_fh <- t_fh %>%\n  mutate(\n    session_start = parse_date_time(session_start, \"%m/%d/%Y %I:%M:%S %p\"),\n    session_end = parse_date_time(session_end, \"%m/%d/%Y %I:%M:%S %p\")\n  ) %>%\n  mutate(Game = \"Forza Horizon 4\")\n\n# Gran Turismo\nt_gts <- read_csv(here(\"Data\", \"telemetry-gran-turismo-sport.csv.gz\")) %>%\n  mutate(\n    Game = \"Gran Turismo Sport\",\n    pid = as.character(pid)\n  )\n\n# Outriders\nt_or <- read_csv(here(\"Data\", \"telemetry-outriders.csv.gz\"))\n# Select relevant variables\nt_or <- t_or %>%\n  select(pid, session_start, session_end) %>%\n  mutate(Game = \"Outriders\")\n\n# The Crew 2\n# Session times are constructed from a signal sent in 5-minute intervals,\n#  therefore if the end timestamp is missing, the session was <5 minutes in duration, and therefore not used\nt_tc2 <- read_csv(here(\"Data\", \"telemetry-the-crew-2.csv.gz\"))\n# Drop <5min sessions and name game\nt_tc2 <- t_tc2 %>% \n  drop_na(session_end) %>% \n  mutate(Game = \"The Crew 2\")\n# Merge games' telemetry to one table\nd_t <- bind_rows(\n  t_acnh, t_al, t_fh, t_gts, t_or, t_tc2\n)"},{"path":"data-wrangling.html","id":"a-note-on-apex-legends-sessions","chapter":"2 Data wrangling","heading":"2.2.1 A note on Apex Legends sessions","text":"Apex Legends “sessions” individual matches, therefore actual gameplay sessions longer duration consist many matches. Therefore looking individual session durations counting number “sessions” Apex Legends misleading. individual sessions interest, first aggregate matches sessions e.g. merging matches occur within say 5 minutes .","code":""},{"path":"data-wrangling.html","id":"clean-sessions","chapter":"2 Data wrangling","heading":"2.2.2 Clean sessions","text":"Calculate hours played sessionA table ranges raw session durations reveals implausible values, can happen e.g. device’s clock improperly configured. therefore remove bad sessions (ones outside total measurement window, negative durations durations greater 10 hours.)\nTable 2.2: Summaries raw session durations\n","code":"\nd_t <- d_t %>%\n  mutate(\n    interval = interval(session_start, session_end)\n  ) %>%\n  mutate(Hours = as.numeric(as.duration(interval)) / 3600)\n# Create indicators for implausible timestamps\nd_t <- d_t %>%\n  mutate(\n    `Session under 0h` = Hours < 0,\n    `Session over 10h` = Hours > 10,\n    `Session before` = session_end < min(d$StartDate) - days(14),\n    `Session after` = session_start > max(d$StartDate)\n  )\n\n# Show a table of raw sessions and potential bad sessions\nd_t %>%\n  select(Game, Hours, starts_with(\"Session \")) %>%\n  tbl_summary(\n    by = Game,\n    statistic = list(all_continuous() ~ \"{median} ({min}, {max})\")\n  ) %>%\n  add_overall() %>%\n  as_kable_extra(caption = \"Summaries of raw session durations\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n# Then remove flagged sessions from data\nd_t <- d_t %>%\n  filter(\n    between(Hours, 0, 10),\n    !`Session before`,\n    !`Session after`\n  )\n\n# And now unnecessary variables\nd_t <- d_t %>% \n  select(-starts_with(\"Session \"))"},{"path":"data-wrangling.html","id":"overlapping-sessions","chapter":"2 Data wrangling","heading":"2.2.2.1 Overlapping sessions","text":"Deal potentially overlapping sessions. function .merge overlapping sessions given participant.Examples overlapping sessionsWe replace original intervals new ones (dropping many rows now redundant set NA), remove now possibly invalid start end times durations (corrected information now contained interval).re-remove sessions longer 10h, created due merging.","code":"\nsource(here(\"R/merge_intervals.R\"))\n# explicitly cache\ndata_path <- here(\"Temp\", \"session-overlap-merged.rds\")\nif (file.exists(data_path)) {\n  message(\"Loading cached data\")\n  d_t <- read_rds(file = data_path)\n} else {\n  message(\n    \"Merging overlapping sessions (grab a coffee, this will take a while)\"\n  )\n  cluster_copy(cluster, c(\"merge_interval\", \"merge_intervals_all\"))\n  d_t <- d_t %>%\n    group_by(pid, Game) %>%\n    partition(cluster) %>%\n    mutate(\n      interval = interval(session_start, session_end)\n    ) %>%\n    arrange(session_start, session_end, .by_group = TRUE) %>%\n    mutate(interval_merged = merge_intervals_all(interval)) %>%\n    collect() %>%\n    ungroup()\n  write_rds(d_t, file = data_path)\n}\nd_t %>%\n  arrange(session_start, session_end) %>%\n  filter(pid == \"de9b7f238ba168b0\") %>%\n  mutate(interval = interval(session_start, session_end)) %>%\n  mutate(overlaps = int_overlaps(interval, lag(interval))) %>% \n  head() %>% \n  kbl() %>% \n  kable_styling(full_width = FALSE, font_size = 12)\nd_t <- d_t %>% \n  select(-interval) %>% \n  rename(interval = interval_merged) %>% \n  drop_na(interval) %>% \n  select(Game, pid, interval)\nd_t <- d_t %>% \n  filter(as.numeric(as.duration(interval))/3600 <= 10)"},{"path":"data-wrangling.html","id":"correlate-sessions-to-waves","chapter":"2 Data wrangling","heading":"2.2.3 Correlate sessions to waves","text":"","code":"\n# Correlate game sessions to waves\n# Start by expanding the survey data to include NAs for waves with no responses. This enables using telemetry for waves where survey wasn't completed.\n\n# Complete data for all pid-wid combinations (all pids have 3 rows; new rows have NAs for all other variables)\nd <- d %>%\n  complete(nesting(Game, pid), wid)\n\n# If a survey wasn't responded to, replace start date with previous wave's date + two weeks. Enables creating a two-week window preceding \"survey response\" to count hours played.\nd <- d %>%\n  arrange(Game, pid, wid) %>%\n  group_by(Game, pid) %>%\n  partition(cluster) %>%\n  # Fill potential missing wave 2 with wave 1 + 14\n  mutate(\n    StartDate = if_else(\n      is.na(StartDate),\n      lag(StartDate, 1) + days(14),\n      StartDate\n    )\n  ) %>%\n  # Fill potential missing wave 3 with wave 2 + 14\n  mutate(\n    StartDate = if_else(\n      is.na(StartDate),\n      lag(StartDate, 1) + days(14),\n      StartDate\n    )\n  ) %>%\n  collect() %>%\n  ungroup()\n\n# The survey data frame now has a row for each participant-wave, even when survey wasn't answered by that participant at that wave.\n\n# Join all play sessions to every wave of each player\nd_t <- d %>%\n  select(Game, pid, wid, StartDate) %>%\n  left_join(d_t)\n\n# Then keep only those sessions that were in that wave's time window:\n# Is session start and/or end within 0-2 weeks preceding survey?\nd_t <- d_t %>%\n  mutate(\n    start_in = int_start(interval) %within%\n      interval(StartDate - days(14), StartDate),\n    end_in = int_end(interval) %within%\n      interval(StartDate - days(14), StartDate)\n  )\nd_t <- d_t %>%\n  filter(start_in | end_in)\n\n# Exact duration depends on if session was completely in window or partially\nd_t <- d_t %>%\n  mutate(\n    Hours = case_when(\n      # Entire session in window: All time counts\n      start_in & end_in ~ as.duration(interval),\n      # Started before window, ended within: start of window to end of session\n      !start_in & end_in ~ as.duration(\n        int_end(interval) - (StartDate - days(14))\n      ),\n      # Started in window, ended after: Session start to end of window\n      start_in & !end_in ~ as.duration(StartDate - int_start(interval))\n    )\n  ) %>%\n  mutate(Hours = as.numeric(Hours) / 3600)"},{"path":"data-wrangling.html","id":"histograms-of-session-durations","chapter":"2 Data wrangling","heading":"2.2.4 Histograms of session durations","text":"look individual sessions’ durations. Recall Apex Legends sessions individual matches look lot shorter.\nFigure 2.1: Histograms individual session durations (taking bad sessions merging overlapping sessions).\n","code":"\nd_t %>%\n  ggplot(aes(Hours)) +\n  geom_histogram() +\n  scale_x_continuous(\n    \"Duration (in hours) of individual sessions\",\n    breaks = pretty_breaks()\n  ) +\n  scale_y_continuous(expand = expansion(c(0, .1))) +\n  facet_wrap(\"Game\", scales = \"free\", ncol = 2)"},{"path":"data-wrangling.html","id":"aggregate-session-durations","chapter":"2 Data wrangling","heading":"2.2.5 Aggregate session durations","text":"Aggregate sum hours waveThese average session numbers hours played total study period\nTable 2.3: Average session numbers hours played whole study\n","code":"\n# Summarise per wave to sum hours and number of sessions\n# this also sets sum hours to zero for people with no telemetry\nd_t <- d_t %>%\n  group_by(Game, pid, wid) %>%\n  summarise(\n    Sessions = sum(!is.na(Hours)),\n    Hours = sum(Hours, na.rm = TRUE) # is 0 if all Hours are NA\n  ) %>%\n  ungroup()\nd_t %>% \n  select(-pid, -wid) %>% \n  tbl_summary(by = Game) %>% \n  add_overall() %>% \n  as_kable_extra(\n    caption = \"Average session numbers and hours played in the whole study\"\n  ) %>% \n  kable_styling(full_width = FALSE, font_size = 12)"},{"path":"data-wrangling.html","id":"merge-telemetry-to-survey-data","chapter":"2 Data wrangling","heading":"2.2.6 Merge telemetry to survey data","text":"","code":"\n# Join back to survey data\nd <- left_join(d, d_t)\n\n# This creates NA hours for people who didn't exist in telemetry,\n# thus we can replace NAs with zeros.\nd <- d %>%\n  mutate(Hours = replace_na(Hours, 0))"},{"path":"data-wrangling.html","id":"exclude-participants-with-no-telemetry","chapter":"2 Data wrangling","heading":"2.2.7 Exclude participants with no telemetry","text":"\nTable 2.4: Summary participants without responses.\n","code":"\n# Indicator if person played at wave\nd <- d %>%\n  mutate(Played = Hours > 0)\n\n# Create participant-level indicator of whether there was any telemetry\nd <- d %>%\n  group_by(Game, pid) %>%\n  mutate(\n    `# of waves with play` = sum(Played),\n    `Any waves with play` = factor(`# of waves with play` > 0)\n  ) %>%\n  ungroup()\n\n# Table of waves with play by game\nd %>%\n  distinct(\n    Game, pid,\n    `# of waves with play`,\n    `Any waves with play`\n  ) %>%\n  select(-pid) %>%\n  tbl_summary(by = Game) %>%\n  add_overall() %>%\n  as_kable_extra(\n    caption = \"Summary of participants with and without responses.\"\n  ) %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n# Take out all who didn't answer a single wave\nd <- filter(d, `Any waves with play` == \"TRUE\")\n\n# Remove the indicators\nd <- select(d, -`# of waves with play`, -`Any waves with play`)"},{"path":"data-wrangling.html","id":"exclude-extreme-player-wave-hours-played","chapter":"2 Data wrangling","heading":"2.2.8 Exclude extreme player-wave hours played","text":"\nTable 2.5: Numbers (%) person-waves 16h/day play\n","code":"\nd %>%\n  mutate(Over_16h_day_telemetry = Hours / 14 > 16) %>%\n  mutate(Over_16h_day_subjective = hours_est / 14 > 16) %>%\n  select(Game, starts_with(\"Over_\")) %>%\n  tbl_summary(by = Game) %>%\n  add_overall() %>%\n  as_kable_extra(\n    caption = \"Numbers (%) of person-waves with more than 16h/day of play\"\n  ) %>% \n  kable_styling(full_width = FALSE, font_size = 12)\nd <- d %>%\n  mutate(\n    Hours = if_else(Hours / 14 > 8, NaN, Hours),\n    hours_est = if_else(hours_est / 14 > 8, NaN, hours_est)\n  )"},{"path":"data-wrangling.html","id":"exclude-bad-survey-intervals","chapter":"2 Data wrangling","heading":"2.3 Exclude bad survey intervals","text":"Participants complete survey waves whenever receiving invitation emails. Therefore participants e.g. complete wave 3 reminded go back wave 2 invitation email . therefore exclude person-waves negative intervals. full join performed . Note, interval NA wave wasn’t completed, resulting unknown values .\nTable 2.6: Numbers (%) person-waves negative intervals\n","code":"\nd %>%\n  mutate(Negative_interval = interval < 0) %>%\n  select(Game, Negative_interval) %>%\n  tbl_summary(by = Game) %>%\n  add_overall() %>%\n  as_kable_extra(\n    caption = \"Numbers (%) of person-waves with negative intervals\"\n  ) %>% \n  kable_styling(full_width = FALSE, font_size = 12)\nd <- d %>%\n  filter(interval > 0 | is.na(interval))"},{"path":"data-wrangling.html","id":"save-cleaned-data","chapter":"2 Data wrangling","heading":"2.4 Save cleaned data","text":"","code":"\nwrite_rds(d, file = here(\"Data\", \"cleaned_data.rds\"), compress = \"gz\")"},{"path":"data-wrangling.html","id":"test-data-cleaning","chapter":"2 Data wrangling","heading":"2.5 Test data cleaning","text":"Run tests cleaned data.","code":"\nlibrary(testthat)\ntest_dir(here(\"R/tests/testthat\"))## ✓ | F W S  OK | Context\n## \n⠏ |         0 | session-overlap                                                 \n⠋ |         1 | session-overlap                                                 \n⠸ |         4 | session-overlap                                                 \n⠼ |         5 | session-overlap                                                 \n✓ |         5 | session-overlap [46.7s]\n## \n## ══ Results ═════════════════════════════════════════════════════════════════════\n## Duration: 46.7 s\n## \n## [ FAIL 0 | WARN 0 | SKIP 0 | PASS 5 ]"},{"path":"data-wrangling.html","id":"system-information","chapter":"2 Data wrangling","heading":"2.6 System information","text":"","code":"\nsessionInfo()## R version 4.1.1 (2021-08-10)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Big Sur 10.16\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices datasets  utils     methods   base     \n## \n## other attached packages:\n##  [1] testthat_3.1.0    sessioninfo_1.1.1 forcats_0.5.1     stringr_1.4.0    \n##  [5] dplyr_1.0.7       purrr_0.3.4       readr_2.0.2       tidyr_1.1.4      \n##  [9] tibble_3.1.5      ggplot2_3.3.5     tidyverse_1.3.1   showtext_0.9-4   \n## [13] showtextdb_3.0    sysfonts_0.8.5    multidplyr_0.1.0  gtsummary_1.4.2  \n## [17] lubridate_1.8.0   scales_1.1.1      here_1.0.1        janitor_2.1.0    \n## [21] kableExtra_1.3.4  knitr_1.36       \n## \n## loaded via a namespace (and not attached):\n##  [1] fs_1.5.0            bit64_4.0.5         webshot_0.5.2      \n##  [4] httr_1.4.2          rprojroot_2.0.2     tools_4.1.1        \n##  [7] backports_1.2.1     bslib_0.3.1         utf8_1.2.2         \n## [10] R6_2.5.1            DBI_1.1.1           colorspace_2.0-2   \n## [13] withr_2.4.2         processx_3.5.2      tidyselect_1.1.1   \n## [16] downlit_0.2.1       bit_4.0.4           curl_4.3.2         \n## [19] compiler_4.1.1      textshaping_0.3.5   cli_3.0.1          \n## [22] rvest_1.0.1         gt_0.3.1            xml2_1.3.2         \n## [25] desc_1.4.0          labeling_0.4.2      stringfish_0.15.2  \n## [28] bookdown_0.24       sass_0.4.0          callr_3.7.0        \n## [31] systemfonts_1.0.2   digest_0.6.28       rmarkdown_2.11     \n## [34] svglite_2.0.0       pkgconfig_2.0.3     htmltools_0.5.2    \n## [37] highr_0.9           dbplyr_2.1.1        fastmap_1.1.0      \n## [40] rlang_0.4.11        readxl_1.3.1        rstudioapi_0.13    \n## [43] farver_2.1.0        RApiSerialize_0.1.0 jquerylib_0.1.4    \n## [46] generics_0.1.0      jsonlite_1.7.2      vroom_1.5.5        \n## [49] magrittr_2.0.1      Matrix_1.3-4        waldo_0.3.1        \n## [52] Rcpp_1.0.7          munsell_0.5.0       fansi_0.5.0        \n## [55] lifecycle_1.0.1     stringi_1.7.5       yaml_2.2.1         \n## [58] snakecase_0.11.0    grid_4.1.1          parallel_4.1.1     \n## [61] crayon_1.4.1        lattice_0.20-45     haven_2.4.3        \n## [64] splines_4.1.1       hms_1.1.1           ps_1.6.0           \n## [67] pillar_1.6.3        pkgload_1.2.2       codetools_0.2-18   \n## [70] reprex_2.0.1        glue_1.4.2          evaluate_0.14      \n## [73] RcppParallel_5.1.4  broom.helpers_1.4.0 renv_0.14.0        \n## [76] modelr_0.1.8        vctrs_0.3.8         tzdb_0.1.2         \n## [79] cellranger_1.1.0    gtable_0.3.0        qs_0.25.1          \n## [82] assertthat_0.2.1    xfun_0.26           broom_0.7.9        \n## [85] ragg_1.1.3          survival_3.2-13     viridisLite_0.4.0  \n## [88] ellipsis_0.3.2"},{"path":"descriptives.html","id":"descriptives","chapter":"3 Descriptives","heading":"3 Descriptives","text":"Load required packages.Figure options.load previously cleaned data table.","code":"\nlibrary(knitr)\nlibrary(scales)\nlibrary(gtsummary)\nlibrary(kableExtra)\nlibrary(here)\nlibrary(showtext)\nlibrary(tidyverse)\nlibrary(lubridate)\n# Plotting options\nFont <- \"Titillium Web\"\nfont_add_google(Font, Font)\ntheme_set(\n  theme_linedraw(\n    base_family = Font,\n    base_size = 12\n  ) +\n    theme(\n      panel.grid.minor = element_blank(),\n      panel.grid.major.x = element_blank()\n    )\n)\ndata_path <- here(\"Data\", \"cleaned_data.rds\")\nif (file.exists(data_path)) {\n  d <- read_rds(file = data_path)\n} else {\n  stop(str_glue(\"{data_path} doesn't exist, run `01-clean.Rmd` to create it.\"))\n}\n\n# Make wave a nicely labelled factor\nd <- d %>%\n  mutate(Wave = factor(wid, levels = 1:3, labels = paste0(\"Wave \", 1:3)))"},{"path":"descriptives.html","id":"demographics-after-exclusions","chapter":"3 Descriptives","heading":"3.1 Demographics after exclusions","text":"\nTable 3.1: Sample demographics\n","code":"\nd %>%\n  filter(wid == 1) %>%\n  distinct(pid, Game, Age, Experience, Gender) %>%\n  select(-pid) %>%\n  tbl_summary(by = Game, missing_text = \"Missing\") %>%\n  add_overall() %>%\n  bold_labels() %>%\n  italicize_levels() %>%\n  as_kable_extra(caption = \"Sample demographics\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)"},{"path":"descriptives.html","id":"survey-descriptives","chapter":"3 Descriptives","heading":"3.2 Survey descriptives","text":"people exclusions.","code":""},{"path":"descriptives.html","id":"response-rate-retention","chapter":"3 Descriptives","heading":"3.2.1 Response rate & retention","text":"\nTable 3.2: Number people (response/retention rate) participating wave.\n","code":"\n# Get data on invite dates and Ns\ninvites <- read_csv(here(\"Data\", \"invites.csv\")) %>%\n  rename(Game = game) %>%\n  mutate(Game = str_replace(Game, \"Animal Crossing: New Horizons\", \"AC:NH\"))\n# Create a table where wave 0 are number of invites,\n# then calculate response rate / retention at each wave.\n# This assumes there are no new participants at wave 3\n# (people who didn't participate in wave 2 showed up at wave 3).\nbind_rows(\n  select(invites, -date),\n  d %>% filter(Responded) %>% count(Game, wid)\n) %>%\n  arrange(Game, wid) %>%\n  group_by(Game) %>%\n  mutate(\n    R_rate = percent(n / lag(n), .01),\n    n = comma(n)\n  ) %>%\n  pivot_wider(names_from = wid, values_from = c(n, R_rate)) %>%\n  mutate(\n    Invites = n_0,\n    `Wave 1` = str_glue(\"{n_1} ({R_rate_1})\"),\n    `Wave 2` = str_glue(\"{n_2} ({R_rate_2})\"),\n    `Wave 3` = str_glue(\"{n_3} ({R_rate_3})\")\n  ) %>%\n  select(Game, Invites:`Wave 3`) %>%\n  mutate(across(everything(), ~ str_replace(., \"NA\", \"0\"))) %>%\n  kbl(caption = \"Number of people (response/retention rate) participating at each wave.\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)"},{"path":"descriptives.html","id":"response-dates","chapter":"3 Descriptives","heading":"3.2.2 Response dates","text":"actual responses (rows survey date filled able join telemetry)\nFigure 3.1: Histograms response dates.\nResponse times\nFigure 3.2: Histograms response times (UTC).\n","code":"\nd %>%\n  # Take only actually responded-to waves\n  filter(Responded) %>%\n  mutate(Date = as_date(StartDate)) %>%\n  count(Game, Wave, Date) %>%\n  ggplot(\n    aes(Date, n, fill = Wave)\n  ) +\n  geom_col() +\n  scale_y_continuous(\n    \"Responses\",\n    breaks = pretty_breaks(10),\n    expand = expansion(c(0, .1)),\n  ) +\n  scale_x_date(\n    \"Date\",\n    date_breaks = \"7 day\", date_labels = \"%b\\n%d\", date_minor_breaks = \"1 day\"\n  ) +\n  facet_wrap(\"Game\", scales = \"free_y\", ncol = 1)\nd %>%\n  filter(Responded) %>%\n  mutate(Hour = hour(StartDate)) %>%\n  count(Game, Wave, Hour) %>%\n  ggplot(aes(Hour, y = n, fill = Wave)) +\n  scale_y_continuous(\n    \"Responses\",\n    breaks = pretty_breaks(10),\n    expand = expansion(c(0, .1)),\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 21, by = 3),\n    expand = expansion(c(0.01))\n  ) +\n  geom_col() +\n  facet_wrap(\"Game\", scales = \"free\", ncol = 2) +\n  theme(legend.position = \"bottom\")"},{"path":"descriptives.html","id":"durations-between-waves","chapter":"3 Descriptives","heading":"3.2.2.1 Durations between waves","text":"Participants respond variable delays due variation email schedules late responding. also check actual intervals completing waves. small values possible participant e.g. completed waves 2 3 succession receiving wave 3 invitation. Note negative values also possible reason excluded . (figure restricted 5-30 day intervals display bulk data.)\nTable 3.3: Interval duration percentiles preceding waves 2 3.\n\nFigure 3.3: Histograms intervals participants completing survey waves (days).\n","code":"\n# Table\nd %>%\n  select(Wave, Game, interval) %>%\n  # group_by(Wave) %>%\n  filter(Wave != \"Wave 1\") %>%\n  summarise(\n    Value = quantile(\n      interval,\n      probs = c(0, .10, .25, .5, .75, .90, 1),\n      na.rm = T\n    ) %>%\n      round(3),\n    Quantile = percent(c(0, .10, .25, .5, .75, .90, 1))\n  ) %>%\n  pivot_wider(names_from = Quantile, values_from = Value) %>%\n  kbl(caption = \"Interval duration percentiles preceding waves 2 and 3.\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n# Figure\nd %>%\n  filter(Wave != \"Wave 1\") %>%\n  filter(between(interval, 5, 30)) %>% \n  mutate(Wave = fct_drop(Wave)) %>%\n  ggplot(aes(interval)) +\n  geom_vline(xintercept = 14, size = .2) +\n  geom_histogram(binwidth = 1, col = \"white\") +\n  scale_y_continuous(\n    \"Count\",\n    expand = expansion(c(0, .1))\n  ) +\n  scale_x_continuous(\n    \"Days between responding\",\n    breaks = pretty_breaks()\n  ) +\n  facet_grid(Game ~ Wave, scales = \"free_y\")"},{"path":"descriptives.html","id":"system-information-1","chapter":"3 Descriptives","heading":"3.3 System information","text":"","code":"\nsessionInfo()## R version 4.1.1 (2021-08-10)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Big Sur 10.16\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices datasets  utils     methods   base     \n## \n## other attached packages:\n##  [1] lubridate_1.8.0  forcats_0.5.1    stringr_1.4.0    dplyr_1.0.7     \n##  [5] purrr_0.3.4      readr_2.0.2      tidyr_1.1.4      tibble_3.1.5    \n##  [9] ggplot2_3.3.5    tidyverse_1.3.1  showtext_0.9-4   showtextdb_3.0  \n## [13] sysfonts_0.8.5   here_1.0.1       kableExtra_1.3.4 gtsummary_1.4.2 \n## [17] scales_1.1.1     knitr_1.36      \n## \n## loaded via a namespace (and not attached):\n##  [1] fs_1.5.0            bit64_4.0.5         webshot_0.5.2      \n##  [4] httr_1.4.2          rprojroot_2.0.2     tools_4.1.1        \n##  [7] backports_1.2.1     bslib_0.3.1         utf8_1.2.2         \n## [10] R6_2.5.1            DBI_1.1.1           colorspace_2.0-2   \n## [13] withr_2.4.2         tidyselect_1.1.1    downlit_0.2.1      \n## [16] bit_4.0.4           curl_4.3.2          compiler_4.1.1     \n## [19] textshaping_0.3.5   cli_3.0.1           rvest_1.0.1        \n## [22] gt_0.3.1            xml2_1.3.2          labeling_0.4.2     \n## [25] bookdown_0.24       sass_0.4.0          systemfonts_1.0.2  \n## [28] digest_0.6.28       rmarkdown_2.11      svglite_2.0.0      \n## [31] pkgconfig_2.0.3     htmltools_0.5.2     dbplyr_2.1.1       \n## [34] fastmap_1.1.0       highr_0.9           rlang_0.4.11       \n## [37] readxl_1.3.1        rstudioapi_0.13     farver_2.1.0       \n## [40] jquerylib_0.1.4     generics_0.1.0      jsonlite_1.7.2     \n## [43] vroom_1.5.5         magrittr_2.0.1      Matrix_1.3-4       \n## [46] Rcpp_1.0.7          munsell_0.5.0       fansi_0.5.0        \n## [49] lifecycle_1.0.1     stringi_1.7.5       yaml_2.2.1         \n## [52] grid_4.1.1          parallel_4.1.1      crayon_1.4.1       \n## [55] lattice_0.20-45     haven_2.4.3         splines_4.1.1      \n## [58] hms_1.1.1           pillar_1.6.3        codetools_0.2-18   \n## [61] reprex_2.0.1        glue_1.4.2          evaluate_0.14      \n## [64] broom.helpers_1.4.0 renv_0.14.0         modelr_0.1.8       \n## [67] vctrs_0.3.8         tzdb_0.1.2          cellranger_1.1.0   \n## [70] gtable_0.3.0        assertthat_0.2.1    xfun_0.26          \n## [73] broom_0.7.9         ragg_1.1.3          survival_3.2-13    \n## [76] viridisLite_0.4.0   ellipsis_0.3.2"},{"path":"main-analysis.html","id":"main-analysis","chapter":"4 Main analysis","heading":"4 Main analysis","text":"document contains main analyses presented manuscript.first load required R packages.Define plotting, table, parallel processing options.analyse data cleaned previously.analyses, game time indicates average number hours per day. telemetry indicates total hours two week window, divide 14 talk average hours per day.","code":"\nlibrary(knitr)\nlibrary(scales)\nlibrary(DT)\nlibrary(kableExtra)\nlibrary(ggpp)\nlibrary(bayestestR)\nlibrary(brms)\nlibrary(here)\nlibrary(ggtext)\nlibrary(ggstance)\nlibrary(ggdist)\nlibrary(patchwork)\nlibrary(lavaan)\nlibrary(showtext)\nlibrary(multidplyr)\nlibrary(tidyverse)\nlibrary(tidybayes)\nlibrary(janitor)\n# parallel computations\nMAX_CORES <- as.numeric(Sys.getenv(\"MAX_CORES\"))\nif (is.na(MAX_CORES)) MAX_CORES <- parallel::detectCores(logical = FALSE)\ncluster <- new_cluster(MAX_CORES)\n\n# load packages on clusters\ncluster_library(cluster, c(\"dplyr\", \"lavaan\"))\n\n# MCMC settings\noptions(mc.cores = 1)\nif (require(\"cmdstanr\")) options(brms.backend = \"cmdstanr\")\n\n# Plotting options\nFont <- \"Titillium Web\"\nfont_add_google(Font, Font)\ntheme_set(\n  theme_linedraw(\n    base_family = Font,\n    base_size = 12\n  ) +\n    theme(\n      panel.grid.minor = element_blank(),\n      panel.grid.major.x = element_blank()\n    )\n)\ncol1 <- \"#2980b9\"\ncol2 <- \"#2980b9\"\ndata_path <- here(\"Data\", \"cleaned_data.rds\")\nif (file.exists(data_path)) {\n  d <- read_rds(file = data_path)\n} else {\n  stop(str_glue(\"{data_path} doesn't exist, run `01-clean.Rmd` to create it.\"))\n}\n\n# Make wave a nicely labelled factor\nd <- d %>%\n  mutate(Wave = factor(wid, levels = 1:3, labels = paste0(\"Wave \", 1:3)))\nd <- d %>%\n  mutate(\n    Hours = Hours / 14,\n    hours_est = hours_est / 14\n  )"},{"path":"main-analysis.html","id":"variables-over-time","chapter":"4 Main analysis","heading":"4.1 Variables over time","text":"Hours played per week cut reasonable value figures:\nTable 4.1: Table hours excluded figure\n\nFigure 4.1: Density plots key variables time.\ntake look simple model change time variable. Note can’t use varying slopes lmer ’s enough data, just random intercepts players.\nTable 4.2: Change time parameter estimates\n","code":"\nd %>%\n  mutate(Hours_over_3 = Hours > 3) %>%\n  tabyl(Hours_over_3) %>%\n  adorn_pct_formatting() %>% \n  kbl(caption = \"Table of hours excluded from figure\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)\ntmp <- d %>%\n  select(\n    Game, Wave, pid,\n    Hours, Affect, `Life satisfaction`,\n    Intrinsic, Extrinsic\n  ) %>%\n  pivot_longer(Hours:Extrinsic) %>%\n  drop_na(value) %>%\n  filter(!(name == \"Hours\" & value > 3)) %>%\n  mutate(name = fct_inorder(name))\n\ntmp %>%\n  ggplot(\n    aes(\n      Wave,\n      value,\n      fill = Game,\n      color, Game,\n      group = Game\n    )\n  ) +\n  scale_x_discrete(labels = 1:3, expand = expansion(c(0.1, .1))) +\n  scale_color_manual(\n    values = c(col1, col2, col1, col2, col1, col2, col1),\n    aesthetics = c(\"fill\", \"color\", \"slab_color\")\n  ) +\n  scale_y_continuous(\n    \"Value\",\n    breaks = pretty_breaks(),\n    expand = expansion(.025)\n  ) +\n  geom_blank() +\n  stat_halfeye(\n    alpha = .33,\n    height = .02,\n    normalize = \"panels\",\n    adjust = 1.1,\n    point_interval = NULL,\n    show.legend = FALSE\n  ) +\n  # only the outline (hackish)\n  stat_halfeye(\n    alpha = 1,\n    height = .02,\n    normalize = \"panels\",\n    aes(slab_color = Game),\n    slab_size = 0.5,\n    fill = NA,\n    adjust = 1.1,\n    point_interval = NULL,\n    show.legend = FALSE\n  ) +\n  stat_summary(\n    fun.data = mean_cl_normal,\n    fatten = 1.25\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"line\",\n    size = .33\n  ) +\n  facet_grid(name ~ Game, scales = \"free_y\") +\n  theme(\n    legend.position = \"none\",\n    strip.text.x = element_text(size = 8)\n  )\nlibrary(lme4)\nlibrary(broom.mixed)\nparameters_change_over_time <- d %>%\n  select(\n    Game, pid, wid,\n    Hours, Intrinsic, Extrinsic,\n    Affect, `Life satisfaction`\n  ) %>%\n  # Put intercept at first wave\n  mutate(Wave = wid - 1) %>%\n  pivot_longer(Hours:`Life satisfaction`, names_to = \"Variable\") %>%\n  group_by(Variable) %>%\n  summarise(\n    lmer(value ~ Wave + (1 | pid) + (1 + Wave | Game), data = cur_data()) %>%\n      tidy(., \"fixed\", conf.int = TRUE)\n  )\nparameters_change_over_time %>%\n  mutate(across(where(is.numeric), ~ format(round(.x, 2), nsmall = 2))) %>%\n  mutate(Result = str_glue(\"{estimate}, 95%CI [{conf.low}, {conf.high}]\")) %>%\n  select(Variable, term, Result) %>%\n  pivot_wider(names_from = term, values_from = Result) %>% \n  kbl(caption = \"Change over time parameter estimates\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)"},{"path":"main-analysis.html","id":"simple-correlation","chapter":"4 Main analysis","heading":"4.2 Simple correlation","text":"informative modelling, estimate simple bivariate regressions key variables.\nFigure 4.2: Unstandardised bivariate regression coefficients models predicting well-. Columns indicate predictors, two rows different well-outcome variables.\n","code":"\nd %>%\n  select(\n    Game, pid, wid, Wave,\n    Hours, hours_est, Intrinsic, Extrinsic,\n    Affect, `Life satisfaction`\n  ) %>%\n  pivot_longer(\n    c(Affect, `Life satisfaction`),\n    names_to = \"Outcome\", values_to = \"Outcome_value\"\n  ) %>%\n  pivot_longer(\n    c(Hours, hours_est, Intrinsic, Extrinsic),\n    names_to = \"Predictor\", values_to = \"Predictor_value\"\n  ) %>%\n  group_by(Game, Outcome, Predictor, Wave) %>%\n  summarise(\n    tidy(\n      lm(\n        Outcome_value ~ Predictor_value, \n        data = cur_data()\n      ), \n      conf.int = TRUE\n    ),\n  ) %>%\n  filter(term != \"(Intercept)\") %>%\n  ggplot(aes(estimate, Game, col = Wave)) +\n  geom_vline(xintercept = 0, lty = 2, size = .25) +\n  scale_x_continuous(\n    \"Bivariate regression coefficient (95%CI)\",\n    breaks = pretty_breaks()\n  ) +\n  geom_pointrangeh(\n    aes(xmin = conf.low, xmax = conf.high),\n    size = .4,\n    position = position_dodge2v(.35)\n  ) +\n  facet_grid(Outcome ~ Predictor) +\n  theme(\n    legend.position = \"bottom\",\n    axis.title.y = element_blank()\n  )"},{"path":"main-analysis.html","id":"riclpm","chapter":"4 Main analysis","heading":"4.3 RICLPM","text":"Wrangle data format lavaan model easier map variable pairs: Wide format different rows outcomes (well-) predictors (hours, needs, motivations).","code":"\nd_riclpm_long <- d %>%\n  select(\n    Game, pid, wid,\n    Hours, hours_est,\n    Intrinsic, Extrinsic,\n    Affect, `Life satisfaction`\n  ) %>%\n  # Long format on well-being scores (outcomes)\n  pivot_longer(\n    c(Affect, `Life satisfaction`),\n    names_to = \"y_var\", values_to = \"y\"\n  ) %>%\n  # Long format on other variables (predictors)\n  pivot_longer(\n    c(Hours, hours_est, Intrinsic, Extrinsic),\n    names_to = \"x_var\", values_to = \"x\"\n  )\nd_riclpm_wide <- d_riclpm_long %>%\n  pivot_wider(names_from = wid, values_from = c(x, y), names_sep = \"\")"},{"path":"main-analysis.html","id":"cross-lagged-scatterplots","chapter":"4 Main analysis","heading":"4.3.1 Cross-lagged scatterplots","text":"\nFigure 4.3: Scatterplots well-(rows indicate variables waves) average hours played per day previous wave. Regression lines GAM fitted lines 95%CIs.\n\nFigure 4.4: Scatterplots well-(rows indicate variables waves) estimated average hours played per day previous wave. Regression lines GAM fitted lines 95%CIs.\n\nFigure 4.5: Scatterplots well-(rows indicate variables waves) intrinsic motivation previous wave. Regression lines GAM fitted lines 95%CIs.\n\nFigure 4.6: Scatterplots well-(rows indicate variables waves) extrinsic motivation previous wave. Regression lines GAM fitted lines 95%CIs.\n\nFigure 4.7: Scatterplots well-(rows indicate variables waves) intrinsic extrinsic motivation previous wave. Regression lines GAM fitted lines 95%CIs.\n","code":"\nOrder <- tibble(\n  y_var = rep(c(\"Affect\", \"Life satisfaction\"), each = 2),\n  wid = c(2, 3, 2, 3),\n  Panel = c(\n    \"Affect[plain('[Wave 2]')]\",\n    \"Affect[plain('[Wave 3]')]\",\n    \"LS[plain('[Wave 2]')]\",\n    \"LS[plain('[Wave 3]')]\"\n  ),\n  Panel_label = fct_inorder(Panel)\n)\n\nd_riclpm_plots <- d_riclpm_long %>%\n  # Take out hours per day over 3 for these plots\n  mutate(x = if_else(str_detect(x_var, \"ours\") & x > 3, NaN, x)) %>%\n  arrange(Game, pid, x_var, wid) %>%\n  group_by(Game, pid, x_var, y_var) %>%\n  mutate(lag_x = lag(x)) %>%\n  left_join(Order) %>%\n  ungroup() %>%\n  filter(wid > 1)\n\nd_riclpm_plots %>%\n  filter(x_var == \"Hours\") %>%\n  ggplot(aes(lag_x, y)) +\n  scale_x_continuous(\n    \"Hours played per day at previous wave\",\n    breaks = pretty_breaks(3)\n  ) +\n  scale_y_continuous(\n    \"Well-being at current wave\",\n    breaks = pretty_breaks()\n  ) +\n  geom_point(size = .2, alpha = .2, shape = 1, col = col1) +\n  geom_smooth(\n    method = \"gam\", size = .4,\n    color = \"black\",\n    alpha = .33, show.legend = FALSE\n  ) +\n  facet_grid(\n    Panel_label ~ Game,\n    scales = \"free_y\",\n    labeller = labeller(.rows = label_parsed)\n  ) +\n  theme(\n    aspect.ratio = 1,\n    panel.grid = element_blank(),\n    strip.text.x = element_text(size = 8)\n  )\n# Plots with other predictors\np_tmp_0 <- last_plot() %+%\n  filter(d_riclpm_plots, x_var == \"hours_est\") +\n  scale_x_continuous(\n    \"Estimated hours played per day at previous wave\",\n    breaks = 0:3\n  )\np_tmp_0\np_tmp_1 <- last_plot() %+%\n  filter(d_riclpm_plots, x_var == \"Intrinsic\") +\n  scale_x_continuous(\n    \"Intrinsic motivation at previous wave\",\n    breaks = pretty_breaks()\n  )\np_tmp_1\np_tmp_2 <- last_plot() %+%\n  filter(d_riclpm_plots, x_var == \"Extrinsic\") +\n  scale_x_continuous(\n    \"Extrinsic motivation at previous wave\",\n    breaks = pretty_breaks()\n  )\np_tmp_2\np_tmp_1 / p_tmp_2"},{"path":"main-analysis.html","id":"fit-one-model-to-all-data","chapter":"4 Main analysis","heading":"4.3.2 Fit one model to all data","text":"First fit RICLPM data. Separately two well-outcomes, predictor (hours, subjective scales). Constrain (cross)lagged parametersSyntax based https://jeroendmulder.github.io/RI-CLPM/lavaan.html\nTable 4.3: RICLPM regression parameters pooled model.\n","code":"\nriclpm_constrained <- \"\n  # Create between components (random intercepts)\n  RIx =~ 1*x1 + 1*x2 + 1*x3\n  RIy =~ 1*y1 + 1*y2 + 1*y3\n\n  # Create within-person centered variables\n  wx1 =~ 1*x1\n  wx2 =~ 1*x2\n  wx3 =~ 1*x3\n  wy1 =~ 1*y1\n  wy2 =~ 1*y2\n  wy3 =~ 1*y3\n\n  # Estimate the lagged effects between the within-person centered variables (constrained).\n  wx2 ~ bx*wx1 + gx*wy1\n  wy2 ~ gy*wx1 + by*wy1\n  wx3 ~ bx*wx2 + gx*wy2\n  wy3 ~ gy*wx2 + by*wy2\n\n  # Estimate the covariance between the within-person centered\n  # variables at the first wave.\n  wx1 ~~ wy1 # Covariance\n\n  # Estimate the covariances between the residuals of the\n  # within-person centered variables (the innovations).\n  wx2 ~~ wy2\n  wx3 ~~ wy3\n\n  # Estimate the variance and covariance of the random intercepts.\n  RIx ~~ RIx\n  RIy ~~ RIy\n  RIx ~~ RIy\n\n  # Estimate the (residual) variance of the within-person centered variables.\n  wx1 ~~ wx1 # Variances\n  wy1 ~~ wy1\n  wx2 ~~ wx2 # Residual variances\n  wy2 ~~ wy2\n  wx3 ~~ wx3\n  wy3 ~~ wy3\n\"\ncluster_copy(cluster, \"riclpm_constrained\")\nfit_riclpm_all <- d_riclpm_wide %>%\n  group_by(y_var, x_var) %>%\n  partition(cluster) %>%\n  summarise(\n    fit = lavaan(\n      riclpm_constrained,\n      data = cur_data(),\n      missing = \"ml\",\n      meanstructure = TRUE,\n      int.ov.free = TRUE\n    ) %>% list()\n  ) %>%\n  collect()\n\nget_lavaan_pars <- function(x) {\n  bind_rows(\n    parameterestimates(x) %>%\n      mutate(Type = \"Unstandardized\"),\n    standardizedsolution(x) %>%\n      rename(est = est.std) %>%\n      mutate(Type = \"Standardized\")\n  ) %>%\n    as_tibble() %>%\n    unite(\"Parameter\", c(lhs, op, rhs), sep = \" \", remove = FALSE)\n}\n\npars_riclpm_avg <- fit_riclpm_all %>%\n  mutate(pars = map(fit, get_lavaan_pars)) %>%\n  select(-fit)\npars_riclpm_avg %>%\n  ungroup() %>%\n  unnest(pars) %>%\n  filter(\n    Parameter %in% c(\"wy2 ~ wx1\", \"wx2 ~ wy1\", \"wy2 ~ wy1\", \"wx2 ~ wx1\"),\n    Type == \"Unstandardized\"\n  ) %>%\n  mutate(across(where(is.numeric), ~ format(round(.x, 2), nsmall = 2))) %>%\n  mutate(Result = str_glue(\"{est}, [{ci.lower}, {ci.upper}]\")) %>%\n  select(y_var, x_var, Parameter, Result) %>%\n  pivot_wider(names_from = Parameter, values_from = Result) %>%\n  kbl(\n    caption = \"RICLPM regression parameters from pooled model.\"\n  ) %>% \n  kable_styling(full_width = FALSE, font_size = 12)"},{"path":"main-analysis.html","id":"separate-models-per-game","chapter":"4 Main analysis","heading":"4.3.3 Separate models per game","text":"Fit model separately game.","code":"\nfit_riclpm_sep <- d_riclpm_wide %>%\n  group_by(y_var, x_var, Game) %>%\n  partition(cluster) %>%\n  summarise(\n    fit = lavaan(\n      riclpm_constrained,\n      data = cur_data(),\n      missing = \"ml\",\n      meanstructure = TRUE,\n      int.ov.free = TRUE\n    ) %>% list()\n  ) %>%\n  collect()\npars_riclpm_sep <- fit_riclpm_sep %>%\n  mutate(pars = map(fit, get_lavaan_pars)) %>%\n  select(-fit)"},{"path":"main-analysis.html","id":"table-of-riclpm-parameters","chapter":"4 Main analysis","heading":"4.3.4 Table of RICLPM parameters","text":"table displays lavaan estimates (game specific pooled).","code":"\npars_riclpm <- pars_riclpm_sep %>%\n  mutate(Model = \"Independent\") %>%\n  bind_rows(pars_riclpm_avg %>% mutate(Model = \"Pooled\", Game = \"Average\")) %>%\n  ungroup() %>%\n  unnest(pars) %>%\n  # Take regression parameters at first interval, and\n  # covariance parameters of interest\n  filter(\n    (str_detect(Parameter, \" ~ \") & !str_detect(Parameter, \"3\")) |\n      Parameter %in% c(\"RIx ~~ RIy\", \"wx1 ~~ wy1\", \"wx2 ~~ wy2\", \"wx3 ~~ wy3\")\n  ) %>%\n  mutate(Game = fct_relevel(Game, \"Average\")) %>%\n  select(-c(lhs:label, z))\n\n# Interactive table so reader can find what they're looking for\npars_riclpm %>% \n  mutate(\n    pvalue = pvalue(pvalue),\n    across(x_var:Game, factor),\n    across(where(is.numeric), ~format(round(.x, 2), nsmall = 2)),\n    Estimate = str_glue(\"{est} [{ci.lower}, {ci.upper}]\")\n  ) %>% \n  select(\n    x_var, y_var, Game, Parameter, Type, Model,\n    Estimate, pvalue\n  ) %>% \n  datatable(\n    filter = \"top\",\n    class = \"display\",\n    rownames = FALSE\n  ) %>% \n  formatStyle(TRUE, `font-size` = '12px')"},{"path":"main-analysis.html","id":"meta-analyses","chapter":"4 Main analysis","heading":"4.4 Meta-analyses","text":"Number observations/participants per model\nTable 4.4: Sample sizes per RICLPM\nconduct meta-analyses (y_var-x_var pair, parameter interest, type parameter (standardized, unstandardized)) game-specific RICLPM parameters.","code":"\nfit_riclpm_sep %>%\n  mutate(N = map_dbl(fit, nobs) %>% comma()) %>%\n  select(-fit) %>%\n  pivot_wider(\n    names_from = x_var,\n    values_from = N,\n    names_glue = \"{x_var} {.value}\"\n  ) %>%\n  rename(Outcome = y_var) %>%\n  arrange(Outcome, Game) %>%\n  kbl(caption = \"Sample sizes per RICLPM\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n# Select variables from RICLPM parameters to data for MA\nd_ma <- pars_riclpm %>%\n  filter(\n    Model == \"Independent\",\n    str_detect(Parameter, \" ~ \")\n  ) %>%\n  select(Type, y_var, x_var, Game, Parameter, est, se, ci.lower, ci.upper)\n\n# Save/load meta-analyses in one file\nfile_path <- here(\"Temp\", \"brms-meta-analyses.rds\")\nif (file.exists(file_path)) {\n  fit_ma <- read_rds(file = file_path)\n} else {\n  # Compile meta-analytic brms/Stan model\n  bf_ma <- bf(est | se(se) ~ 0 + Intercept + (0 + Intercept | Game))\n  fit_ma_empty <- brm(\n    bf_ma,\n    data = d_ma,\n    prior = prior(student_t(7, 0, 0.25), class = \"sd\", group = \"Game\") +\n      prior(normal(0, 0.5), class = \"b\"),\n    chains = 0,\n    control = list(adapt_delta = .999)\n  )\n  # Fit meta-analyses by updating the compiled model.\n  cluster_library(cluster, c(\"brms\", \"dplyr\"))\n  cluster_copy(cluster, \"fit_ma_empty\")\n  fit_ma <- d_ma %>%\n    group_by(x_var, y_var, Parameter, Type) %>%\n    partition(cluster) %>%\n    summarise(\n      fit = list(\n        update(\n          fit_ma_empty,\n          newdata = cur_data(),\n          control = list(adapt_delta = .9999),\n          iter = 10000, warmup = 5000,\n          refresh = 0\n        )\n      )\n    ) %>%\n    collect() %>%\n    ungroup()\n  write_rds(fit_ma, file = file_path)\n}\n\n# Function to get varying and average effects' posteriors from brmsfit\nget_ma_post <- function(x) {\n  coef(x, summary = FALSE) %>%\n    .[[\"Game\"]] %>%\n    .[, , 1] %>%\n    as.data.frame() %>%\n    cbind(fixef(x, summary = FALSE)) %>%\n    as_tibble()\n}"},{"path":"main-analysis.html","id":"table-of-parameters","chapter":"4 Main analysis","heading":"4.4.1 Table of parameters","text":"resulting parameters listed table .","code":"\n# Table of all parameters from meta-analyses\nma_pars <- fit_ma %>%\n  mutate(out = map(fit, get_ma_post)) %>%\n  mutate(\n    out2 = map(\n      out,\n      ~ describe_posterior(.x, centrality = \"mean\", ci = 0.95) %>%\n        rename(Game = Parameter)\n    )\n  ) %>%\n  select(-fit, -out) %>%\n  unnest(out2) %>%\n  select(-CI, -starts_with(\"ROPE\")) %>%\n  mutate(Game = str_replace(Game, \"Intercept\", \"Average\"))\n\n# Interactive table so reader can find what they're looking for\nma_pars %>% \n  mutate(\n    pd = percent(pd, .1),\n    across(x_var:Game, factor),\n    across(where(is.numeric), ~format(round(.x, 2), nsmall = 2)),\n    Estimate = str_glue(\"{Mean} [{CI_low}, {CI_high}]\")\n  ) %>% \n  select(x_var:Game, Estimate, pd) %>% \n  datatable(\n    filter = \"top\",\n    class = \"display\",\n    rownames = FALSE\n  ) %>% \n  formatStyle(TRUE, `font-size` = '12px')"},{"path":"main-analysis.html","id":"average-effects","chapter":"4 Main analysis","heading":"4.4.2 Average effects","text":"figure shows average (across games) effects meta-analyses game-specific lavaan fits (“partial pooling”) completely pooled lavaan model (one model fit games’ data). Unstandardized parameters shown.\nFigure 4.8: Average RICLPM regression parameters pooled meta-analytic models. Columns different x variables, rows different y variables. e.g. wy2 ~ wy1 indicates lagged effect y previous timepoint y current timepoint.\n","code":"\nma_pars %>%\n  filter(Game == \"Average\", Type == \"Unstandardized\") %>%\n  ggplot(aes(Mean, Parameter)) +\n  scale_x_continuous(\n    \"Estimated parameter (95%CI)\",\n    breaks = pretty_breaks()\n  ) +\n  scale_color_discrete(\"Model\") +\n  geom_vline(xintercept = 0, lty = 2, size = .25) +\n  geom_pointrangeh(\n    aes(xmin = CI_low, xmax = CI_high, color = \"Partially pooled\")\n  ) +\n  geom_pointrangeh(\n    data = pars_riclpm %>%\n      filter(\n        str_detect(Parameter, \" ~ \"),\n        Type == \"Unstandardized\",\n        Model == \"Pooled\"\n      ),\n    aes(x = est, xmin = ci.lower, xmax = ci.upper, color = \"Pooled\"),\n    position = position_nudge(y = .15)\n  ) +\n  facet_grid(y_var ~ x_var) +\n  guides(\n    color = guide_legend(direction = \"vertical\")\n  ) +\n  theme(legend.position = \"bottom\")"},{"path":"main-analysis.html","id":"hours---wb","chapter":"4 Main analysis","heading":"4.4.3 Hours <-> WB","text":"Draw forest plot meta-analyses hours. First, define informative labels correct order , load function drawing forest plots.\nFigure 4.9: Forest plots meta-analytic raw cross-lagged regression coefficients models examining average hours played per day well-. Shaded curves indicate approximate posterior densities, numerically summarised means 95%CIs right margin. Numbers average effects indicate posterior probabilities direction.\n\nFigure 4.10: Figure also displaying underlying lavaan fits’ point estimates 95%CIs.\n","code":"\n# Table of nice labels in proper order\nOrder <- distinct(fit_ma, x_var, y_var, Parameter) %>%\n  ungroup() %>%\n  # Meta-analyses only for regression parameters\n  filter(str_detect(Parameter, \" ~ \")) %>%\n  mutate(\n    x_lab = case_when(\n      x_var == \"Hours\" ~ \"Play\",\n      x_var == \"Intrinsic\" ~ \"Intrinsic\",\n      x_var == \"Extrinsic\" ~ \"Extrinsic\",\n      x_var == \"hours_est\" ~ \"Estimated~hours\"\n    ),\n    y_lab = case_when(\n      y_var == \"Affect\" ~ \"Affect\",\n      y_var == \"Life satisfaction\" ~ \"Life~satisfaction\"\n    ),\n    Panel_label = case_when(\n      Parameter == \"wx2 ~ wx1\" ~\n        str_glue('{x_lab}[plain(\"[t-1]\")]%->%{x_lab}[plain(\"[t]\")]'),\n      Parameter == \"wy2 ~ wy1\" ~\n        str_glue('{y_lab}[plain(\"[t-1]\")]%->%{y_lab}[plain(\"[t]\")]'),\n      Parameter == \"wy2 ~ wx1\" ~\n        str_glue('{x_lab}[plain(\"[t-1]\")]%->%{y_lab}[plain(\"[t]\")]'),\n      Parameter == \"wx2 ~ wy1\" ~\n        str_glue('{y_lab}[plain(\"[t-1]\")]%->%{x_lab}[plain(\"[t]\")]')\n    )\n  ) %>%\n  mutate(\n    Parameter_order = factor(\n      Parameter,\n      levels = c(\"wy2 ~ wx1\", \"wx2 ~ wy1\", \"wy2 ~ wy1\", \"wx2 ~ wx1\")\n    )\n  ) %>%\n  arrange(Parameter_order, y_var) %>%\n  mutate(Panel_label = fct_inorder(Panel_label))\n\n# Functions in R/\nsource(here(\"R\", \"meta-analysis-helpers.R\"))\nfit_ma_sum <- summarize_ma(fit_ma)\nfp_1 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Hours\",\n  parameters = c(\"wy2 ~ wx1\"),\n  lavaan = FALSE,\n  x_limits = c(-.3, .4)\n)\nfp_2 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Hours\",\n  parameters = c(\"wx2 ~ wy1\"),\n  lavaan = FALSE,\n  x_limits = c(-.05, .06)\n)\n(fp_1 + theme(axis.title.x = element_blank())) / fp_2\n# Also see in comparison to lavaan model estimates\nfp_1 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Hours\",\n  parameters = c(\"wy2 ~ wx1\"),\n  lavaan = TRUE,\n  x_limits = c(-.3, .4)\n)\nfp_2 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Hours\",\n  parameters = c(\"wx2 ~ wy1\"),\n  lavaan = TRUE,\n  x_limits = c(-.05, .06)\n)\n(fp_1 + theme(axis.title.x = element_blank())) / fp_2"},{"path":"main-analysis.html","id":"experiences---wb","chapter":"4 Main analysis","heading":"4.4.4 Experiences <-> WB","text":"\nFigure 4.11: Forest plots meta-analytic raw cross-lagged regression coefficients models examining motivations well-(motivations well-). Shaded curves indicate approximate posterior densities, numerically summarised means 95%CIs right margin. Numbers average effects indicate posterior probabilities direction.\n\nFigure 4.12: Forest plots meta-analytic raw cross-lagged regression coefficients models examining motivations well-(well-motivations). Shaded curves indicate approximate posterior densities, numerically summarised means 95%CIs right margin. Numbers average effects indicate posterior probabilities direction.\n","code":"\nfp_1 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Intrinsic\",\n  parameters = c(\"wy2 ~ wx1\"),\n  lavaan = FALSE,\n  x_limits = c(-.2, .5)\n) +\n  theme(axis.title.x = element_blank())\nfp_2 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Intrinsic\",\n  parameters = c(\"wx2 ~ wy1\"),\n  lavaan = FALSE,\n  x_limits = c(-.15, .35)\n) +\n  theme(axis.title.x = element_blank())\nfp_3 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Extrinsic\",\n  parameters = c(\"wy2 ~ wx1\"),\n  lavaan = FALSE,\n  x_limits = c(-.5, .4)\n) +\n  theme(axis.title.x = element_blank())\nfp_4 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Extrinsic\",\n  parameters = c(\"wx2 ~ wy1\"),\n  lavaan = FALSE,\n  x_limits = c(-.35, .35)\n)\nfp_1 / fp_3\nfp_2 / fp_4"},{"path":"main-analysis.html","id":"autocorrelations","chapter":"4 Main analysis","heading":"4.4.5 Autocorrelations","text":"\nFigure 4.13: Forest plots meta-analytic raw lagged regression coefficients models examining average hours played well-, showing well-autocorrelations. Shaded curves indicate approximate posterior densities, numerically summarised means 95%CIs right margin. Numbers average effects indicate posterior probabilities direction.\n","code":"\nforest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"Hours\",\n  parameters = c(\"wy2 ~ wy1\"),\n  lavaan = TRUE,\n  x_limits = c(-.1, .8)\n) +\n  scale_x_continuous(\n    \"Estimated lagged effect\",\n    breaks = pretty_breaks()\n  )"},{"path":"main-analysis.html","id":"some-post-hoc-calculations","chapter":"4 Main analysis","heading":"4.4.6 Some post-hoc calculations","text":"model parameters report effects one-unit (e.g. one hour per day) changes predictor outcome. also expand first asking effect average deviation predictor outcome. , example, calculate average range players’ average daily hours played, answer effect average player moving smallest greatest amount play well-.\nTable 4.5: ES average hours per week WB\nturn second question, much average player need increase play result subjectively noticeable effect. Anvari Lakens estimated 2% movement might lower limit subjectively noticeable change well-using similar measurement scale.calculate, predictor outcome, much predictor need change order elicit change outcome greater subjective threshold. e.g. many hours one need play “feel ”.\nTable 4.6: Estimated required change X elicit subjectively noticeable change well-outcomes\nmuch posterior density within ROPE defined &L subjectively noticeable limits?\nTable 4.7: ROPE percentages threshold\n","code":"\n# Average ranges of predictors\navg_ranges <- d %>%\n  # Calculate range for everyone (returns -Inf if all values missing)\n  group_by(Game, pid) %>%\n  summarise(\n    across(\n      c(Intrinsic, Extrinsic, Hours, hours_est),\n      .fns = ~max(.x, na.rm = TRUE) - min(.x, na.rm = TRUE)\n    )\n  ) %>% \n  ungroup() %>% \n  # Calculate grand mean range excluding -Inf values\n  summarise(\n    across(\n      Intrinsic:hours_est, \n      ~mean(if_else(.x==-Inf, NaN, .x), na.rm = TRUE)\n    )\n  ) %>% \n  pivot_longer(\n    everything(),\n    names_to = \"x_var\",\n    values_to = \"Mean_range\"\n  )\nfit_ma %>%\n  filter(\n    Type == \"Unstandardized\",\n    Parameter == \"wy2 ~ wx1\"\n  ) %>%\n  left_join(avg_ranges) %>% \n  mutate(\n    hypothesis = map2(\n      fit,\n      Mean_range,\n      ~ hypothesis(.x, str_glue(\"Intercept * {.y} = 0\")) %>% .[[1]]\n    )\n  ) %>%\n  unnest(hypothesis) %>%\n  select(x_var, y_var, Mean_range, Parameter, Estimate:CI.Upper) %>%\n  kbl(digits = 3, caption = \"ES of average hours per week on WB\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n# Subjective threshold for each outcome\nsubjective_thresholds <- tibble(\n  y_var = c(\"Affect\", \"Life satisfaction\"),\n  Threshold = 0.02 * c(13, 11)\n)\n\n# Table of effects and thresholds\nfit_ma_sum$summary %>% \n  filter(\n    Type == \"Unstandardized\",\n    Parameter == \"wy2 ~ wx1\",\n    Game == \"Average\"\n  ) %>% \n  select(x_var, y_var, Effect = Mean) %>% \n  arrange(x_var, y_var) %>% \n  left_join(subjective_thresholds) %>% \n  mutate(`Change needed` = Threshold / abs(Effect)) %>% \n  kbl(\n    digits = 2, \n    caption = \"Estimated required change in X to elicit a subjectively noticeable change in well-being outcomes\"\n  ) %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n# Table of percentages of effects' posterior distributions with ROPE (as defined by thresholds for being subjectively noticed)\nfit_ma %>%\n  filter(\n    Parameter == \"wy2 ~ wx1\",\n    Type == \"Unstandardized\"\n  ) %>%\n  left_join(subjective_thresholds) %>% \n  mutate(\n    out = map2(\n      fit,\n      Threshold,\n      ~ describe_posterior(.x, rope_range = c(-.y, .y), rope_ci = 1) %>%\n        select(-Parameter)\n    )\n  ) %>%\n  unnest(out) %>%\n  select(x_var, y_var, Threshold, CI_low, CI_high, ROPE_Percentage) %>%\n  mutate(ROPE_Percentage = percent(ROPE_Percentage, .1)) %>%\n  kbl(\n    digits = 2,\n    caption = \"ROPE percentages below threshold\"\n  ) %>% \n  kable_styling(full_width = FALSE, font_size = 12)"},{"path":"main-analysis.html","id":"subjective-time","chapter":"4 Main analysis","heading":"4.5 Subjective time","text":"Comparing subjective hours estimates objective play behaviour complicated fact missing value objective behaviour indicates zero hours play, whereas missing value estimated time can indicate either estimated lack play, missing response (e.g. player declined respond item). Therefore comparison done individuals provided subjective estimate data.Histograms hours played (behaviour: top, strong; estimated: bottom, light). person-waves variables present included.\nFigure 4.14: Bivariate histograms average hours played per day wave (columns) game (rows). Histograms zero, strong colour, reflect behavioural telemetry log data. Histograms zero, light colour, indicate subjective estimates play. Histogram heights normalized counts. Small triangles indicate means.\nscatterplot subjective objective time. person-waves variables present included.\nFigure 4.15: Scatterplots subjectively estimated average hours daily play objective behavioural hours played. Dashed line indicates identity, solid lines simple regression lines. Small blue points individual participants, solid dark points bivariate sample means.\nWave-person differences. Difference indicates estimate - behaviour, positive numbers indicate overestimates.\nFigure 4.16: Density curves differences subjectively estimated objectively logged average daily play time.\n\nTable 4.8: Estimation errors (Estimated - Behaviour)\n","code":"\ntmp <- d %>%\n  drop_na(Hours, hours_est) %>%\n  group_by(Game, pid, Wave) %>%\n  summarise(\n    Hours = sum(Hours, na.rm = T),\n    hours_est = sum(hours_est, na.rm = T)\n  ) %>%\n  group_by(Game, Wave) %>%\n  summarise(\n    across(c(Hours, hours_est), .fns = list(m = mean, se = ~ sd(.x) / sqrt(length(.x))))\n  )\n\nd %>%\n  select(Game, pid, Wave, Hours, hours_est) %>%\n  drop_na(Hours, hours_est) %>%\n  filter(Hours < 3, hours_est < 3) %>%\n  ggplot(aes()) +\n  scale_y_continuous(\n    \"Normalised count\",\n    breaks = pretty_breaks()\n  ) +\n  scale_x_continuous(breaks = pretty_breaks()) +\n  geom_histogram(\n    aes(x = Hours, y = stat(ncount)),\n    bins = 30, fill = col1, col = \"white\", alpha = .75\n  ) +\n  geom_histogram(\n    aes(x = hours_est, y = stat(ncount) * -1),\n    bins = 30, fill = col1, col = \"white\", alpha = .5\n  ) +\n  geom_pointrangeh(\n    data = tmp, shape = 25, fill = col1, alpha = 1,\n    aes(\n      x = Hours_m,\n      xmin = Hours_m - Hours_se,\n      xmax = Hours_m + Hours_se,\n      y = .075,\n    )\n  ) +\n  geom_pointrangeh(\n    data = tmp, shape = 24, fill = col1, alpha = .75,\n    aes(\n      x = hours_est_m,\n      xmin = hours_est_m - hours_est_se,\n      xmax = hours_est_m + hours_est_se,\n      y = -.075\n    )\n  ) +\n  facet_grid(Game ~ Wave, scales = \"free\")\nd %>%\n  drop_na(Hours, hours_est) %>%\n  filter(Hours < 3, hours_est < 3) %>%\n  select(Game, pid, Wave, Objective = Hours, Subjective = hours_est) %>%\n  ggplot(aes(Objective, Subjective)) +\n  scale_x_continuous(\n    \"Hours played per day (behaviour)\",\n    breaks = c(0, 1, 2, 3), labels = c(0, 1, 2, 3)\n  ) +\n  scale_y_continuous(\n    \"Hours played per day (estimate)\",\n    breaks = pretty_breaks()\n  ) +\n  geom_point(size = .2, alpha = .2, shape = 1, col = col1) +\n  geom_abline(intercept = 0, slope = 1, lty = 2, size = .25) +\n  stat_centroid() +\n  geom_smooth(\n    method = \"lm\", size = .4,\n    color = \"black\",\n    alpha = .33, show.legend = FALSE\n  ) +\n  facet_grid(Wave ~ Game) +\n  theme(aspect.ratio = 1)\nd %>%\n  select(Game, pid, Wave, Hours, hours_est) %>%\n  mutate(Difference = hours_est - Hours) %>%\n  filter(Hours < 3, hours_est < 3) %>%\n  drop_na(Difference) %>%\n  ggplot(aes(Difference, Game)) +\n  scale_x_continuous(\n    \"Estimation error (hours/day)\",\n    breaks = pretty_breaks()\n  ) +\n  coord_cartesian(xlim = c(-0.5, 0.5)) +\n  geom_vline(xintercept = 0, lty = 2, size = .25) +\n  stat_halfeye(point_interval = NULL) +\n  stat_summaryh(fun.data = mean_cl_boot_h) +\n  facet_wrap(\"Wave\", ncol = 1)\n# Overall confidence interval for estimation error\nd %>%\n  select(Game, pid, Wave, Hours, hours_est) %>%\n  mutate(Difference = hours_est - Hours) %>%\n  filter(Hours < 3, hours_est < 3) %>%\n  drop_na(Difference) %>%\n  group_by(Wave) %>%\n  summarise(mean_cl_boot(Difference)) %>%\n  kbl(digits = 2, caption = \"Estimation errors (Estimated - Behaviour)\") %>% \n  kable_styling(full_width = FALSE, font_size = 12)"},{"path":"main-analysis.html","id":"meta-analysis","chapter":"4 Main analysis","heading":"4.5.1 Meta-analysis","text":"\nFigure 4.17: Forest plots meta-analytic raw cross-lagged regression coefficients models examining subjectively estimated average hours played per day well-. Shaded curves indicate approximate posterior densities, numerically summarised means 95%CIs right margin. Numbers average effects indicate posterior probabilities direction.\n","code":"\nfp_1 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"hours_est\",\n  parameters = c(\"wy2 ~ wx1\"),\n  lavaan = TRUE,\n  x_limits = c(-.35, .55)\n)\nfp_2 <- forest_plot(\n  object = fit_ma_sum,\n  type = \"Unstandardized\",\n  x_var = \"hours_est\",\n  parameters = c(\"wx2 ~ wy1\"),\n  lavaan = TRUE,\n  x_limits = c(-.15, .2)\n)\nfp_1 / fp_2"},{"path":"main-analysis.html","id":"system-information-2","chapter":"4 Main analysis","heading":"4.6 System information","text":"","code":"\nsessionInfo()## R version 4.1.1 (2021-08-10)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Big Sur 10.16\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices datasets  utils     methods   base     \n## \n## other attached packages:\n##  [1] broom.mixed_0.2.7 lme4_1.1-27.1     Matrix_1.3-4      cmdstanr_0.4.0   \n##  [5] janitor_2.1.0     tidybayes_3.0.1   forcats_0.5.1     stringr_1.4.0    \n##  [9] dplyr_1.0.7       purrr_0.3.4       readr_2.0.2       tidyr_1.1.4      \n## [13] tibble_3.1.5      tidyverse_1.3.1   multidplyr_0.1.0  showtext_0.9-4   \n## [17] showtextdb_3.0    sysfonts_0.8.5    lavaan_0.6-9      patchwork_1.1.1  \n## [21] ggdist_3.0.0      ggstance_0.3.5    ggtext_0.1.1      here_1.0.1       \n## [25] brms_2.16.1       Rcpp_1.0.7        bayestestR_0.11.0 ggpp_0.4.2       \n## [29] ggplot2_3.3.5     kableExtra_1.3.4  DT_0.19           scales_1.1.1     \n## [33] knitr_1.36       \n## \n## loaded via a namespace (and not attached):\n##   [1] utf8_1.2.2           tidyselect_1.1.1     htmlwidgets_1.5.4   \n##   [4] grid_4.1.1           munsell_0.5.0        codetools_0.2-18    \n##   [7] ragg_1.1.3           miniUI_0.1.1.1       withr_2.4.2         \n##  [10] Brobdingnag_1.2-6    colorspace_2.0-2     highr_0.9           \n##  [13] rstudioapi_0.13      stats4_4.1.1         bayesplot_1.8.1     \n##  [16] rstan_2.21.2         mnormt_2.0.2         farver_2.1.0        \n##  [19] datawizard_0.2.1     bridgesampling_1.1-2 rprojroot_2.0.2     \n##  [22] coda_0.19-4          vctrs_0.3.8          generics_0.1.0      \n##  [25] xfun_0.26            R6_2.5.1             markdown_1.1        \n##  [28] gamm4_0.2-6          projpred_2.0.2       assertthat_0.2.1    \n##  [31] promises_1.2.0.1     nnet_7.3-16          gtable_0.3.0        \n##  [34] downlit_0.2.1        processx_3.5.2       rlang_0.4.11        \n##  [37] systemfonts_1.0.2    splines_4.1.1        broom_0.7.9         \n##  [40] checkmate_2.0.0      inline_0.3.19        yaml_2.2.1          \n##  [43] reshape2_1.4.4       abind_1.4-5          modelr_0.1.8        \n##  [46] threejs_0.3.3        crosstalk_1.1.1      backports_1.2.1     \n##  [49] httpuv_1.6.3         rsconnect_0.8.24     Hmisc_4.6-0         \n##  [52] gridtext_0.1.4       tensorA_0.36.2       tools_4.1.1         \n##  [55] bookdown_0.24        ellipsis_0.3.2       RColorBrewer_1.1-2  \n##  [58] jquerylib_0.1.4      posterior_1.1.0      ggridges_0.5.3      \n##  [61] plyr_1.8.6           base64enc_0.1-3      ps_1.6.0            \n##  [64] prettyunits_1.1.1    rpart_4.1-15         zoo_1.8-9           \n##  [67] cluster_2.1.2        haven_2.4.3          fs_1.5.0            \n##  [70] magrittr_2.0.1       data.table_1.14.2    colourpicker_1.1.1  \n##  [73] reprex_2.0.1         tmvnsim_1.0-2        mvtnorm_1.1-2       \n##  [76] matrixStats_0.61.0   stringfish_0.15.2    qs_0.25.1           \n##  [79] hms_1.1.1            shinyjs_2.0.0        mime_0.12           \n##  [82] evaluate_0.14        arrayhelpers_1.1-0   xtable_1.8-4        \n##  [85] shinystan_2.5.0      jpeg_0.1-9           readxl_1.3.1        \n##  [88] gridExtra_2.3        rstantools_2.1.1     compiler_4.1.1      \n##  [91] V8_3.4.2             crayon_1.4.1         minqa_1.2.4         \n##  [94] StanHeaders_2.21.0-7 htmltools_0.5.2      mgcv_1.8-38         \n##  [97] later_1.3.0          tzdb_0.1.2           Formula_1.2-4       \n## [100] RcppParallel_5.1.4   RApiSerialize_0.1.0  lubridate_1.8.0     \n## [103] DBI_1.1.1            dbplyr_2.1.1         MASS_7.3-54         \n## [106] boot_1.3-28          cli_3.0.1            parallel_4.1.1      \n## [109] insight_0.14.4       igraph_1.2.6         pkgconfig_2.0.3     \n## [112] foreign_0.8-81       xml2_1.3.2           svUnit_1.0.6        \n## [115] dygraphs_1.1.1.6     pbivnorm_0.6.0       svglite_2.0.0       \n## [118] bslib_0.3.1          webshot_0.5.2        rvest_1.0.1         \n## [121] snakecase_0.11.0     distributional_0.2.2 callr_3.7.0         \n## [124] digest_0.6.28        rmarkdown_2.11       cellranger_1.1.0    \n## [127] htmlTable_2.2.1      curl_4.3.2           shiny_1.7.1         \n## [130] gtools_3.9.2         nloptr_1.2.2.2       lifecycle_1.0.1     \n## [133] nlme_3.1-153         jsonlite_1.7.2       viridisLite_0.4.0   \n## [136] fansi_0.5.0          pillar_1.6.3         lattice_0.20-45     \n## [139] loo_2.4.1            survival_3.2-13      fastmap_1.1.0       \n## [142] httr_1.4.2           pkgbuild_1.2.0       glue_1.4.2          \n## [145] xts_0.12.1           png_0.1-7            shinythemes_1.2.0   \n## [148] stringi_1.7.5        sass_0.4.0           textshaping_0.3.5   \n## [151] latticeExtra_0.6-29  renv_0.14.0"}]
